{
 "metadata": {
  "name": "",
  "signature": "sha256:0f8d36c390761a85d4a1eaf8cff3f1cc7878e7828b3948e61b8646bb4e76397c"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Model Evaluation"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Review of last class\n",
      "\n",
      "- Goal was to predict the species of an **unknown iris**\n",
      "- Made predictions using KNN models with **different values of K**\n",
      "- Need a way to choose the **\"best\" model**: the one that \"generalizes\" to \"out-of-sample\" data\n",
      "\n",
      "**Solution:** Create a procedure that **estimates** how well a model is likely to perform on out-of-sample data and use that to choose between models."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Evaluation procedure #1: Train and test on the entire dataset"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "1. Train the model on the **entire dataset**.\n",
      "2. Test the model on the **same dataset**, and evaluate how well we did by comparing the **predicted** response values with the **true** response values."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# read the iris data into a DataFrame\n",
      "import pandas as pd\n",
      "url = 'http://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'\n",
      "col_names = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species']\n",
      "iris = pd.read_csv(url, header=None, names=col_names)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# map each iris species to a number\n",
      "iris['species_num'] = iris.species.map({'Iris-setosa':0, 'Iris-versicolor':1, 'Iris-virginica':2})"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# store feature matrix in \"X\"\n",
      "feature_cols = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']\n",
      "X = iris[feature_cols]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# store response vector in \"y\"\n",
      "y = iris.species_num"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### KNN (K=50)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# import the class\n",
      "from sklearn.neighbors import KNeighborsClassifier\n",
      "\n",
      "# instantiate the model\n",
      "knn = KNeighborsClassifier(n_neighbors=50)\n",
      "\n",
      "# train the model on the entire dataset\n",
      "knn.fit(X, y)\n",
      "\n",
      "# predict the response values for the observations in X (\"test the model\")\n",
      "knn.predict(X)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# store the predicted response values\n",
      "y_pred = knn.predict(X)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To evaluate a model, we also need an **evaluation metric:**\n",
      "\n",
      "- Numeric calculation used to **quantify** the performance of a model\n",
      "- Appropriate metric depends on the **goals** of your problem\n",
      "\n",
      "Most common choices for classification problems:\n",
      "\n",
      "- **Classification accuracy**: percentage of correct predictions (reward function)\n",
      "- **Classification error**: percentage of incorrect predictions (loss function)\n",
      "\n",
      "In this case, we'll use classification accuracy."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# compute classification accuracy\n",
      "from sklearn import metrics\n",
      "print metrics.accuracy_score(y, y_pred)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This is known as **training accuracy** because we are testing the model on the same data we used to train the model."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "![50NN classification map](images/iris_50nn_map.png)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### KNN (K=1)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "knn = KNeighborsClassifier(n_neighbors=1)\n",
      "knn.fit(X, y)\n",
      "y_pred = knn.predict(X)\n",
      "print metrics.accuracy_score(y, y_pred)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Does that mean that K=1 is the best value for K?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "![1NN classification map](images/iris_01nn_map.png)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Problems with training and testing on the same data\n",
      "\n",
      "- Goal is to estimate likely performance of a model on **out-of-sample data**\n",
      "- But, maximizing training accuracy rewards **overly complex models** that won't necessarily generalize\n",
      "- Unnecessarily complex models **overfit** the training data:\n",
      "    - Will do well when tested using the in-sample data\n",
      "    - May do poorly on out-of-sample data\n",
      "    - Learns the \"noise\" in the data rather than the \"signal\"\n",
      "    - From Quora: [What is an intuitive explanation of overfitting?](http://www.quora.com/What-is-an-intuitive-explanation-of-overfitting/answer/Jessica-Su)\n",
      "\n",
      "**Thus, training accuracy is not a good estimate of out-of-sample accuracy.**"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Evaluation procedure #2: Train/test split"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "1. Split the dataset into two pieces: a **training set** and a **testing set**.\n",
      "2. Train the model on the **training set**.\n",
      "3. Test the model on the **testing set**, and evaluate how well we did."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Side note on \"unpacking\""
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def min_max(nums):\n",
      "    smallest = min(nums)\n",
      "    largest = max(nums)\n",
      "    return [smallest, largest]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "min_and_max = min_max([1, 2, 3])\n",
      "print min_and_max\n",
      "print type(min_and_max)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "the_min, the_max = min_max([1, 2, 3])\n",
      "print the_min\n",
      "print type(the_min)\n",
      "print the_max\n",
      "print type(the_max)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Understanding the `train_test_split` function"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cross_validation import train_test_split\n",
      "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# before splitting\n",
      "print X.shape\n",
      "\n",
      "# after splitting\n",
      "print X_train.shape\n",
      "print X_test.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# before splitting\n",
      "print y.shape\n",
      "\n",
      "# after splitting\n",
      "print y_train.shape\n",
      "print y_test.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "![train_test_split](images/train_test_split.png)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "What does this accomplish?\n",
      "\n",
      "- Model will be trained and tested on **different data** (we treat testing data like out-of-sample data)\n",
      "- Response values are **known** for the testing set, and thus **predictions can be evaluated**\n",
      "- **Testing accuracy** is a better estimate than training accuracy of out-of-sample performance"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Using the train/test split procedure (K=1)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# STEP 1: split X and y into training and testing sets (using random_state parameter for reproducibility)\n",
      "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=4)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# STEP 2: train the model on the training set (using K=1)\n",
      "knn = KNeighborsClassifier(n_neighbors=1)\n",
      "knn.fit(X_train, y_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# STEP 3: test the model on the testing set, and check the accuracy\n",
      "y_pred = knn.predict(X_test)\n",
      "print metrics.accuracy_score(y_test, y_pred)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Repeat for K=50"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "knn = KNeighborsClassifier(n_neighbors=50)\n",
      "knn.fit(X_train, y_train)\n",
      "y_pred = knn.predict(X_test)\n",
      "print metrics.accuracy_score(y_test, y_pred)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "![Bias-variance tradeoff](images/bias_variance.png)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Search for the \"best\" value of K"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# calculate TRAINING ERROR and TESTING ERROR for K=1 through 50\n",
      "k_range = range(1, 51)\n",
      "training_error = []\n",
      "testing_error = []\n",
      "for k in k_range:\n",
      "    knn = KNeighborsClassifier(n_neighbors=k)\n",
      "    # training error\n",
      "    knn.fit(X, y)\n",
      "    y_pred = knn.predict(X)\n",
      "    training_error.append(1 - metrics.accuracy_score(y, y_pred))\n",
      "    # testing error\n",
      "    knn.fit(X_train, y_train)\n",
      "    y_pred = knn.predict(X_test)\n",
      "    testing_error.append(1 - metrics.accuracy_score(y_test, y_pred))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "import matplotlib.pyplot as plt\n",
      "plt.style.use('ggplot')\n",
      "\n",
      "# plot the relationship between K and TESTING ERROR\n",
      "plt.plot(k_range, testing_error)\n",
      "plt.xlabel('Value of K for KNN')\n",
      "plt.ylabel('Testing Error')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "What can we conclude?\n",
      "\n",
      "- A value of K around 11 is likely the **best value for K** when using KNN on the iris dataset.\n",
      "- When given the measurements of an **unknown iris**, we estimate that we would be able to correctly predict its species 98% of the time."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Training error versus testing error"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# create a DataFrame of K, training error, and testing error\n",
      "df = pd.DataFrame({'K': k_range, 'train':training_error, 'test':testing_error}).set_index('K')\n",
      "df.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# plot the relationship between K and both TRAINING ERROR and TESTING ERROR\n",
      "df.plot()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Roughly speaking:\n",
      "\n",
      "- **Training error** decreases as model complexity increases (lower value of K)\n",
      "- **Testing error** is minimized at the optimum model complexity"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "![Bias-variance tradeoff](images/training_testing_error.png)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Making predictions on out-of-sample data"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Given the measurements of a (truly) unknown iris, how do we predict its species?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# instantiate the model with the best known parameters\n",
      "knn = KNeighborsClassifier(n_neighbors=11)\n",
      "\n",
      "# re-train the model with X and y (not X_train and y_train) - why?\n",
      "knn.fit(X, y)\n",
      "\n",
      "# make a prediction for an out-of-sample observation\n",
      "knn.predict([3, 5, 4, 2])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Disadvantages of train/test split?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "What would happen if the `train_test_split` function had split the data differently? Would we get the same exact results as before?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# try different values for random_state\n",
      "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=4)\n",
      "knn = KNeighborsClassifier(n_neighbors=50)\n",
      "knn.fit(X_train, y_train)\n",
      "y_pred = knn.predict(X_test)\n",
      "print metrics.accuracy_score(y_test, y_pred)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- Testing accuracy is a **high-variance estimate** of out-of-sample accuracy\n",
      "- **K-fold cross-validation** overcomes this limitation and provides more reliable estimates\n",
      "- But, train/test split is still useful because of its **flexibility and speed**"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}